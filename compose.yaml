x-common:
  &common
  logging:
    driver: local
  restart: unless-stopped
  healthcheck:
    &common-healthcheck
    start_period: 30s
    start_interval: 5s
    interval: 30s
    retries: 5

x-airflow-common:
  &airflow-common
  <<: *common
  build: docker/airflow
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:${AIRFLOW_DATABASE_PASSWORD:-airflow}@postgres/airflow
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: 'http://airflow:8080/execution/'
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY:-}
    AIRFLOW__CORE__INTERNAL_API_SECRET_KEY: ${AIRFLOW_API_SECRET_KEY:-airflow-core-internal-api-secret-key}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_WWW_SECRET_KEY:-airflow-webserver-secret-key}
    AIRFLOW__API_AUTH__JWT_SECRET: ${AIRFLOW_JWT_KEY:-airflow-api-auth-jwt-secret}
    CONNECTION_CHECK_MAX_COUNT: 100
    CONNECTION_CHECK_SLEEP_TIME: 5
  volumes:
    - ./dags:/opt/airflow/dags
  healthcheck:
    &airflow-common-healthcheck
    start_period: 60s
    start_interval: 15s
    interval: 60s
    retries: 5

x-spark-common:
  &spark-common
  <<: *common
  image: spark:3.5.6-java17
  healthcheck:
    &spark-common-healthcheck
    <<: *common-healthcheck


services:
  postgres:
    <<: *common
    image: postgres:17.5
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      FLEET_DATABASE_PASSWORD: ${FLEET_DATABASE_PASSWORD:-fleet}
      AIRFLOW_DATABASE_PASSWORD: ${AIRFLOW_DATABASE_PASSWORD:-airflow}
      GRAFANA_DATABASE_PASSWORD: ${GRAFANA_DATABASE_PASSWORD:-grafana}
      SUPERSET_DATABASE_PASSWORD: ${SUPERSET_DATABASE_PASSWORD:-superset}
      READER_DATABASE_PASSWORD: ${READER_DATABASE_PASSWORD:-reader}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init.sh:/docker-entrypoint-initdb.d/init.sh
      - ./fleet/db.sql:/opt/fleet/db.sql
    ports:
      - '127.0.0.1:5432:5432'
    hostname: postgres
    healthcheck:
      <<: *common-healthcheck
      test: timeout 5 pg_isready -h localhost -U postgres >/dev/null || exit 1

  clickhouse:
    <<: *common
    image: clickhouse:25.3.3.42
    environment:
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-default}
      FLEET_WAREHOUSE_PASSWORD: ${FLEET_WAREHOUSE_PASSWORD:-fleet}
      READER_WAREHOUSE_PASSWORD: ${READER_WAREHOUSE_PASSWORD:-reader}
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
      CLICKHOUSE_DO_NOT_CHOWN: 1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./docker/clickhouse/conf.xml:/etc/clickhouse-server/config.d/conf.xml
      - ./docker/clickhouse/init.sh:/docker-entrypoint-initdb.d/init.sh
      - ./fleet/schema.sql:/opt/fleet/schema.sql
      - ./data:/var/lib/clickhouse/user_files
    ports:
      - '127.0.0.1:8123:8123'
      - '127.0.0.1:9000:9000'
    hostname: clickhouse
    healthcheck:
      <<: *common-healthcheck
      test: timeout 5 wget --no-verbose --tries=1 --spider http://localhost:8123/ping || exit 1

  redis:
    <<: *common
    image: redis:8.0.2
    volumes:
      - redis_data:/data
    ports:
      - '127.0.0.1:6379:6379'
    hostname: redis
    healthcheck:
      <<: *common-healthcheck
      test: timeout 5 redis-cli ping >/dev/null || exit 1

  airflow:
    <<: *airflow-common
    command: api-server
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_PASSWORD:-airflow}
      _AIRFLOW_WWW_USER_FIRSTNAME: Airflow
      _AIRFLOW_WWW_USER_LASTNAME: Admin
      _AIRFLOW_WWW_USER_EMAIL: admin@localhost
      FLEET_DATABASE_PASSWORD: ${FLEET_DATABASE_PASSWORD:-fleet}
      FLEET_WAREHOUSE_PASSWORD: ${FLEET_WAREHOUSE_PASSWORD:-fleet}
      OPENSKY_CLIENT_ID: ${OPENSKY_CLIENT_ID:?required}
      OPENSKY_CLIENT_SECRET: ${OPENSKY_CLIENT_SECRET:?required}
    ports:
      - '127.0.0.1:8080:8080'
    hostname: airflow
    healthcheck:
      <<: *airflow-common-healthcheck
      test: timeout 5 curl -f -sS http://localhost:8080/api/v2/version >/dev/null || exit 1

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    hostname: airflow-scheduler
    healthcheck:
      <<: *airflow-common-healthcheck
      test: timeout 10 airflow jobs check --job-type SchedulerJob --local >/dev/null || exit 1

  airflow-dag-processor:
    <<: *airflow-common
    command: dag-processor
    hostname: airflow-dag-processor
    healthcheck:
      <<: *airflow-common-healthcheck
      test: timeout 10 airflow jobs check --job-type DagProcessorJob --local >/dev/null || exit 1

  spark:
    <<: *spark-common
    command: /opt/spark/sbin/start-master.sh
    environment:
      SPARK_NO_DAEMONIZE: 1
    ports:
      - '127.0.0.1:8081:8080'
      - '127.0.0.1:7077:7077'
    hostname: spark
    healthcheck:
      <<: *spark-common-healthcheck
      test: timeout 5 curl -f -sS http://localhost:8080/ >/dev/null || exit 1

  spark-worker:
    <<: *spark-common
    command: /opt/spark/sbin/start-worker.sh spark://spark:7077
    environment:
      SPARK_NO_DAEMONIZE: 1
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_CORES: 1
    hostname: spark-worker
    healthcheck:
      <<: *spark-common-healthcheck
      test: timeout 5 curl -f -sS http://localhost:8081/ >/dev/null || exit 1
    scale: 4

  grafana:
    <<: *common
    image: grafana/grafana:12.0.1
    environment:
      GF_DATABASE_TYPE: postgres
      GF_DATABASE_HOST: postgres
      GF_DATABASE_NAME: grafana
      GF_DATABASE_USER: grafana
      GF_DATABASE_PASSWORD: grafana
      GF_REMOTE_CACHE_TYPE: redis
      GF_REMOTE_CACHE_CONNSTR: addr=redis:6379,db=2
      GF_ADMIN_USER: admin
      GF_ADMIN_PASSWORD: admin
      GF_ADMIN_EMAIL: admin@localhost
      GF_PLUGINS_PREINSTALL: grafana-clickhouse-datasource
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /opt/fleet/dashboards/home.json
      READER_DATABASE_PASSWORD: ${READER_DATABASE_PASSWORD:-reader}
      READER_WAREHOUSE_PASSWORD: ${READER_WAREHOUSE_PASSWORD:-reader}
    volumes:
      - ./docker/grafana/dashboards:/opt/fleet/dashboards
      - ./docker/grafana/provisioning:/etc/grafana/provisioning
    ports:
      - '127.0.0.1:3000:3000'
    hostname: grafana
    healthcheck:
      <<: *common-healthcheck
      test: timeout 5 curl -f -sS http://localhost:3000/api/health >/dev/null || exit 1

  superset:
    <<: *common
    build: docker/superset
    command: /opt/fleet/bootstrap.sh
    environment:
      SUPERSET_DATABASE_URL: postgresql://superset:${SUPERSET_DATABASE_PASSWORD:-superset}@postgres/superset
      SUPERSET_REDIS_URL: redis://redis:6379/3
      SUPERSET_SECRET_KEY: superset-secret-key
      SUPERSET_CONFIG_PATH: /opt/fleet/superset_config.py
      SUPERSET_ADMIN_USERNAME: ${SUPERSET_ADMIN_USERNAME:-admin}
      SUPERSET_ADMIN_PASSWORD: ${SUPERSET_ADMIN_PASSWORD:-admin}
      SUPERSET_ADMIN_FIRSTNAME: Superset
      SUPERSET_ADMIN_LASTNAME: Admin
      SUPERSET_ADMIN_EMAIL: admin@localhost
      READER_DATABASE_PASSWORD: ${READER_DATABASE_PASSWORD:-reader}
      READER_WAREHOUSE_PASSWORD: ${READER_WAREHOUSE_PASSWORD:-reader}
      MAPBOX_API_KEY: ${MAPBOX_API_KEY:-}
    volumes:
      - ./docker/superset/bootstrap.sh:/opt/fleet/bootstrap.sh
      - ./docker/superset/superset_config.py:/opt/fleet/superset_config.py
      - ./docker/superset/init.sh:/opt/fleet/init.sh
      - ./docker/superset/provision.sh:/opt/fleet/provision.sh
      - ./docker/superset/provisioning:/opt/fleet/provisioning
    ports:
      - '127.0.0.1:8088:8088'
    hostname: superset
    healthcheck:
      test: timeout 5 curl -f -sS http://localhost:8088/health >/dev/null || exit 1


volumes:
  postgres_data:
  clickhouse_data:
  redis_data:


networks:
  default:
    name: fleet
